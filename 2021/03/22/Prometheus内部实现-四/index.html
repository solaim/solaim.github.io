<!DOCTYPE html>
<html lang="zh-CN">
    
    <head>
    <meta charset="utf-8">
    <meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, viewport-fit=cover" name="viewport" />
    <meta name="description" content="Prometheus内部实现(四)" />
    <meta name="hexo-theme-A4" content="v1.9.7" />
    <link rel="alternate icon" type="image/webp" href="/img/favicon.webp">
    <title>Coronarium | Drill down</title>

    
        
<link rel="stylesheet" href="/css/highlight/style1.css">

        
<link rel="stylesheet" href="/css/reset.css">

        
<link rel="stylesheet" href="/css/markdown.css">

        
<link rel="stylesheet" href="/css/fonts.css">
 
         <!--注意：首页既不是post也不是page-->
        
        
        
<link rel="stylesheet" href="/css/ui.css">
 
        
<link rel="stylesheet" href="/css/style.css">


        
            <!--返回顶部css-->
            
<link rel="stylesheet" href="/css/returnToTop.css">

            
<link rel="stylesheet" href="/css/unicons.css">

        
        
            <!--目录-->
            
<link rel="stylesheet" href="/css/toc.css">

        
    

    
        
<link rel="stylesheet" href="/css/returnToLastPage.css">

    
    
   
<link rel="stylesheet" href="/css/lightgallery-bundle.min.css">


<meta name="generator" content="Hexo 6.3.0"></head>
    
    

    
    



    

    
    

    
    <style>
        :root {
            --waline-theme-color: #9e5345; 
            --waline-color: #9e5345; 
            --waline-border-color: #9e5345; 
            --waline-white: #9e5345; 
            --waline-bgcolor-light: #efeae2;  
        }
        body {
            color: #9e5345;
            background: #e8e0c9;
        }
        .post-md code {
            background: #e4e4e4;
            color: #2e5041; 
        }
        .post-md pre, .post-md .highlight {
            background: #e4e4e4;
            color: #2e5041; 
        }
        pre .string, pre .value, pre .inheritance, pre .header, pre .ruby .symbol, pre .xml .cdata {
            color: #9e5345;
        }
        pre .number, pre .preprocessor, pre .built_in, pre .literal, pre .params, pre .constant {
            color: #9e5345;
        }
        .year-font-color {
            color: #9e5345 !important;
        }
        .wl-card span.wl-nick {
            color: #9e5345; 
        }
        .wl-card .wl-badge {
            border: 1px solid #9e5345;
            color: #9e5345; 
        }
        .wl-btn {
            border: 1px solid #9e5345; 
            color:  #9e5345;  
        }
        .wl-btn.primary {
            color: #efeae2; 
        }
        .wl-header label {
            color: #9e5345;
        }
        a {
            color: #2e5041;
        }

        .post-md a {
            color: #2e5041;
        }

        .nav li a {
            color: #2e5041;
        }

        .archive-main a:link {
            color: #2e5041;
        }
        .archive-main a:visited {
            color: #9c9caf; 
        }

        .archive li span {
            color: #9e5345;
        }

        .post-main-title {
            color: #9e5345;
        }

        .post-md h1,
        .post-md h2,
        .post-md h3,
        .post-md h4,
        .post-md h5,
        .post-md h6 {
            color: #9e5345;
        }

        [data-waline] p {
            color: #9e5345;
        }
        [data-waline] a {
            color: #9e5345;
        } 
        .wl-sort li.active {
            color: #9e5345;
        }

        .wl-card .wl-meta>span {
            background: #efeae2;
        }

        .paper {
            background: #e8e0c9;
        }

        .index-main {
            background: #efeae2;
        }

        .paper-main {
            background: #efeae2;
        }

        .wl-panel {
            background: #efeae2;
        }

        .archive li:nth-child(odd) {
            background: #efeae2;
            ;
        }

        .archive li:nth-child(even) {
            background: #efeae2;
        }

        .post-md table tr:nth-child(odd) td {
            background: #efeae2;
        }

        .post-md table tr:nth-child(even) td {
            background: #efeae2;
        }

    
        .progress-wrap::after {
            color: #9e5345; /* 箭头的颜色 */
        }
        .progress-wrap svg.progress-circle path {
	        stroke: #9e5345; /* 边框的颜色 */
        }
        .progress-wrap::before {
	        background-image: linear-gradient(298deg, #2e5041, #2e5041); /* 鼠标滑过的箭头颜色 */
         }

        .return-to-last-progress-wrap::after {
            color: #9e5345; /* 箭头的颜色 */
        }
        .return-to-last-progress-wrap svg.progress-circle path {
	        stroke: #9e5345; /* 边框的颜色 */
        }
        .return-to-last-progress-wrap::before {
	        background-image: linear-gradient(298deg, #2e5041, #2e5041); /* 鼠标滑过的箭头颜色 */
         }

         .left-toc-container::-webkit-scrollbar-thumb {
            background-color: #9e5345; /* 设置滚动条拖动块的颜色 */
        }

        .bs-docs-sidebar .nav>.active>a,
        .bs-docs-sidebar .nav>li>a:hover,
        .bs-docs-sidebar .nav>li>a:focus {
            color: #2e5041;
            border-left-color: #2e5041;
        }
        .bs-docs-sidebar .nav>li>a {
            color:  #9e5345;
        }
    </style>

    
    
    <body>
        <script src="/js/darkmode-js.min.js"></script>
        
        <script>
            const options = {
                bottom: '40px', // default: '32px'
                right: 'unset', // default: '32px'
                left: '42px', // default: 'unset'
                time: '0.3s', // default: '0.3s'
                mixColor: '#fff', // default: '#fff'
                backgroundColor: ' #e8e0c9  ',  // default: '#fff'
                buttonColorDark: '#100f2c',  // default: '#100f2c'
                buttonColorLight: '#fff', // default: '#fff'
                saveInCookies: true, // default: true,
                label: '🌓', // default: ''
                autoMatchOsTheme: true // default: true
            }
            const darkmode = new Darkmode(options);
            darkmode.showWidget();
        </script>
        
        
            <div class="left-toc-container">
                <nav id="toc" class="bs-docs-sidebar"></nav>
            </div>
        
        <div class="paper">
            
            
            
            
                <div class="shadow-drop-2-bottom paper-main">
                    


<div class="header">
    <div class="header-container">
        <style>
            .header-img {
                width: 56px;
                height: auto;
                object-fit: cover; /* 保持图片比例 */
                transition: transform 0.3s ease-in-out; 
                border-radius: 0; 
            }
            
        </style>
        <img 
            alt="^-^" 
            cache-control="max-age=86400" 
            class="header-img" 
            src="/img/favicon.webp" 
        />
        <div class="header-content">
            <a class="logo" href="/">Coronarium</a> 
            <span class="description">专注、探索、积累</span> 
        </div>
    </div>
    
   
    <ul class="nav">
        
            
                <li><a href="/">首页</a></li>
            
        
            
                <li><a href="/list/">文章</a></li>
            
        
            
                <li><a href="/about/">关于</a></li>
            
        
    </ul>
</div> 
        
                    
                    

                    
                    
                    
                    <!--说明是文章post页面-->
                    
                        <div class="post-main">
    

    
        
            
                <div class="post-main-title" style="text-align: center;">
                    Prometheus内部实现(四)
                </div>
            
        
      
    

    

        
            <div class="post-head-meta-center">
        
                
                    <span>最近更新：2023-09-10</span> 
                
                
                    
                        &nbsp; | &nbsp;
                    
                     <span>字数总计：2.5k</span>
                
                
                    
                        &nbsp; | &nbsp;
                    
                    <span>阅读估时：12分钟</span>
                
                
                    
                        &nbsp; | &nbsp;
                    
                    <span id="busuanzi_container_page_pv">
                        阅读量：<span id="busuanzi_value_page_pv"></span>次
                    </span>
                
            </div>
    

    <div class="post-md">
        
            
                
            
        
        <div class=".article-gallery"><blockquote>
<p>目标该怎么管理？静态还是动态发现？</p>
</blockquote>
<p>目标管理是使用静态还是动态发现，这个和基础架构有关，要回答这个问题，需要先说说应用部署的现状！</p>
<p><a href="/img/virtual-container.webp" title="virtual-container" class="gallery-item" style="box-shadow: none;"> <img src="/img/virtual-container.webp" alt="virtual-container"></a></p>
<p>目前，企业应用部署有两种选项：</p>
<ol>
<li>基于虚拟机</li>
<li>基于容器</li>
</ol>
<p>当然，更多的是虚拟机里装docker，算是两者的结合，节省成本。</p>
<p>那么基于虚拟机部署应用有什么特点呢？就是变化小，你的预期和实际情况是相对静止的，在虚拟机上部署一套应用，一套流程走下来，大概得小半天吧，这种情况把要监控的目标写到Prometheus的配置文件，再重启Prometheus server，完全玩得转！</p>
<p>然而，当公司的应用开始基于容器部署，特别是管控平面使用了k8s，那么手动配置Prometheus、重启就成为了噩梦一样的存在！运维会疲于奔命，开发会吐槽运维。</p>
<p>所以监控目标的配置，取决于使用的底层技术！</p>
<blockquote>
<p>题外话：要想Devops在企业落地，得有一整套配套的工具，整体打通。</p>
</blockquote>
<p>那么Prometheus在抓取目标方面是怎么做的呢？我们先重温一下相关组件的启动：</p>
<pre><code class="go">&#123;
  // Scrape discovery manager.
  g.Add(
    func() error &#123;
      err := discoveryManagerScrape.Run()
      level.Info(logger).Log(&quot;msg&quot;, &quot;Scrape discovery manager stopped&quot;)
      return err
    &#125;,
    func(err error) &#123;
      level.Info(logger).Log(&quot;msg&quot;, &quot;Stopping scrape discovery manager...&quot;)
      cancelScrape()
    &#125;,
  )
&#125;
&#123;
  // Notify discovery manager.
  ...
&#125;
&#123;
  // Scrape manager.
  g.Add(
    func() error &#123;
      // When the scrape manager receives a new targets list
      // it needs to read a valid config for each job.
      // It depends on the config being in sync with the discovery manager so
      // we wait until the config is fully loaded.
      &lt;-reloadReady.C

      err := scrapeManager.Run(discoveryManagerScrape.SyncCh())
      level.Info(logger).Log(&quot;msg&quot;, &quot;Scrape manager stopped&quot;)
      return err
    &#125;,
    func(err error) &#123;
      // Scrape manager needs to be stopped before closing the local TSDB
      // so that it doesn&#39;t try to write samples to a closed storage.
      level.Info(logger).Log(&quot;msg&quot;, &quot;Stopping scrape manager...&quot;)
      scrapeManager.Stop()
    &#125;,
  )
&#125;
</code></pre>
<p>启动的核心语句：</p>
<pre><code class="go"># 启动动态发现
discoveryManagerScrape.Run()

# 启动目标抓取
scrapeManager.Run(discoveryManagerScrape.SyncCh())
</code></pre>
<p><code>discoveryManagerScrape.SyncCh()</code>作为参数传递给<code>scrapeManager.Run</code>，来看看它的实现：</p>
<pre><code class="go">// SyncCh returns a read only channel used by all the clients to receive target updates.
func (m *Manager) SyncCh() &lt;-chan map[string][]*targetgroup.Group &#123;
    return m.syncCh
&#125;
</code></pre>
<p>实际上，是将discoveryManagerScrape和scrapeManager通过<code>map[string][]*targetgroup.Group</code>channel 连接了起来，也就是discoveryManagerScrape动态发现的目标通过这个channel，同步给scrapeManager，scrapeManager负责抓取。</p>
<p>我们来做一个小结：</p>
<p><a href="/img/dsm.jpg" title="dsm" class="gallery-item" style="box-shadow: none;"> <img src="/img/dsm.jpg" alt="dsm"></a></p>
<p>其实，就是两个goroutine之间通过channel通信。</p>
<p>接下来，让我们看看<code>scrapeManager.Run</code>里面的实现：</p>
<pre><code class="go">// Run receives and saves target set updates and triggers the scraping loops reloading.
// Reloading happens in the background so that it doesn&#39;t block receiving targets updates.
func (m *Manager) Run(tsets &lt;-chan map[string][]*targetgroup.Group) error &#123;
    go m.reloader()
    for &#123;
        select &#123;
        case ts := &lt;-tsets:
            m.updateTsets(ts)

            select &#123;
            case m.triggerReload &lt;- struct&#123;&#125;&#123;&#125;:
            default:
            &#125;

        case &lt;-m.graceShut:
            return nil
        &#125;
    &#125;
&#125;
</code></pre>
<p>核心是一个for循环，channel tsets(map[string][]*targetgroup.Group)等待动态发现传递的目标，调用<code>m.updateTsets(ts)</code>更新抓取的目标，设置reload信号<code>m.triggerReload &lt;- struct&#123;&#125;&#123;&#125;</code>，周而复始，先来看看<code>m.updateTsets(ts)</code>坐了什么操作：</p>
<pre><code class="go">func (m *Manager) updateTsets(tsets map[string][]*targetgroup.Group) &#123;
    m.mtxScrape.Lock()
    m.targetSets = tsets
    m.mtxScrape.Unlock()
&#125;
</code></pre>
<p>没错，很简单，将监控的目标进行了更新。再来，看看Manager结构体的定义：</p>
<pre><code class="go">type Manager struct &#123;
    logger    log.Logger
    append    storage.Appendable
    graceShut chan struct&#123;&#125;

    jitterSeed    uint64     // Global jitterSeed seed is used to spread scrape workload across HA setup.
    mtxScrape     sync.Mutex // Guards the fields below.
    scrapeConfigs map[string]*config.ScrapeConfig
    scrapePools   map[string]*scrapePool
    targetSets    map[string][]*targetgroup.Group

    triggerReload chan struct&#123;&#125;
&#125;
</code></pre>
<p>可以看到跟抓取有关的三个字段为：</p>
<pre><code class="go">    scrapeConfigs map[string]*config.ScrapeConfig
    scrapePools   map[string]*scrapePool
    targetSets    map[string][]*targetgroup.Group
</code></pre>
<p>现在，discoveryManagerScrape通过channel将抓取的目标传递过来，scrapeManager内部到底是怎样转化成最后的HTTP请求呢？</p>
<p>scrapeManager.Run有一个重要的语句<code>go m.reloader()</code>，并在接收目标后设置了<code>triggerReload</code></p>
<pre><code class="go">func (m *Manager) reloader() &#123;
    ticker := time.NewTicker(5 * time.Second)
    defer ticker.Stop()

    for &#123;
        select &#123;
        case &lt;-m.graceShut:
            return
        case &lt;-ticker.C:
            select &#123;
            case &lt;-m.triggerReload:
                m.reload()
            case &lt;-m.graceShut:
                return
            &#125;
        &#125;
    &#125;
&#125;
</code></pre>
<p>Prometheus server每隔5秒，检查triggerReload channel，调用<code>m.reload()</code></p>
<pre><code class="go">func (m *Manager) reload() &#123;
    m.mtxScrape.Lock()
    var wg sync.WaitGroup
    for setName, groups := range m.targetSets &#123;
        if _, ok := m.scrapePools[setName]; !ok &#123;
            scrapeConfig, ok := m.scrapeConfigs[setName]
            if !ok &#123;
                level.Error(m.logger).Log(&quot;msg&quot;, &quot;error reloading target set&quot;, &quot;err&quot;, &quot;invalid config id:&quot;+setName)
                continue
            &#125;
            sp, err := newScrapePool(scrapeConfig, m.append, m.jitterSeed, log.With(m.logger, &quot;scrape_pool&quot;, setName))
            if err != nil &#123;
                level.Error(m.logger).Log(&quot;msg&quot;, &quot;error creating new scrape pool&quot;, &quot;err&quot;, err, &quot;scrape_pool&quot;, setName)
                continue
            &#125;
            m.scrapePools[setName] = sp
        &#125;

        wg.Add(1)
        // Run the sync in parallel as these take a while and at high load can&#39;t catch up.
        go func(sp *scrapePool, groups []*targetgroup.Group) &#123;
            sp.Sync(groups)
            wg.Done()
        &#125;(m.scrapePools[setName], groups)

    &#125;
    m.mtxScrape.Unlock()
    wg.Wait()
&#125;
</code></pre>
<p>这个方法完成了核心的转换，将目标转换成可以执行的任务，抽出核心业务我们可以得到这样的范式：</p>
<pre><code class="go">
var wg sync.WaitGroup
for _, t := range tsets &#123;
  wg.Add(1)
  go func(t int) &#123;
    wg.Done()
  &#125;(t)
&#125;
wg.Wait()
</code></pre>
<p>回到业务上，我们发现targetSets、scrapeConfigs和scrapePools进行了完美的转换，如果scrapePools没有setName，并且scrapeConfigs有相应的配置，则调用<code>newScrapePool</code>创建scrapePool，更新到Manager，最后将scrapePool和[]*targetgroup.Group传递给匿名函数，完成<code>sp.Sync(groups)</code>调用，然我们继续跟踪Sync方法：</p>
<pre><code class="go">func (sp *scrapePool) Sync(tgs []*targetgroup.Group) &#123;
    sp.mtx.Lock()
    defer sp.mtx.Unlock()
    start := time.Now()

    sp.targetMtx.Lock()
    var all []*Target
    sp.droppedTargets = []*Target&#123;&#125;
    for _, tg := range tgs &#123;
        targets, err := targetsFromGroup(tg, sp.config)
        if err != nil &#123;
            level.Error(sp.logger).Log(&quot;msg&quot;, &quot;creating targets failed&quot;, &quot;err&quot;, err)
            continue
        &#125;
        for _, t := range targets &#123;
            if t.Labels().Len() &gt; 0 &#123;
                all = append(all, t)
            &#125; else if t.DiscoveredLabels().Len() &gt; 0 &#123;
                sp.droppedTargets = append(sp.droppedTargets, t)
            &#125;
        &#125;
    &#125;
    sp.targetMtx.Unlock()
    sp.sync(all)

    targetSyncIntervalLength.WithLabelValues(sp.config.JobName).Observe(
        time.Since(start).Seconds(),
    )
    targetScrapePoolSyncsCounter.WithLabelValues(sp.config.JobName).Inc()
&#125;
</code></pre>
<p>Sync方法的核心有两个调用：</p>
<pre><code class="go"># 将Group转化成Target列表
targets, err := targetsFromGroup(tg, sp.config)

# 同步
sp.sync(all)
</code></pre>
<p>Target的定义如下：</p>
<pre><code class="go">type Target struct &#123;
    // Labels before any processing.
    discoveredLabels labels.Labels
    // Any labels that are added to this target and its metrics.
    labels labels.Labels
    // Additional URL parameters that are part of the target URL.
    params url.Values

    mtx                sync.RWMutex
    lastError          error
    lastScrape         time.Time
    lastScrapeDuration time.Duration
    health             TargetHealth
    metadata           MetricMetadataStore
&#125;
</code></pre>
<p>这就是要抓取一个目标的所有配置，基本信息都包含在这里面了，现在配置转化成了可以执行的目标，我们看看<code>sp.sync</code>的具体实现：</p>
<pre><code class="go">// sync takes a list of potentially duplicated targets, deduplicates them, starts
// scrape loops for new targets, and stops scrape loops for disappeared targets.
// It returns after all stopped scrape loops terminated.
func (sp *scrapePool) sync(targets []*Target) &#123;
    var (
        uniqueLoops     = make(map[uint64]loop)
        interval        = time.Duration(sp.config.ScrapeInterval)
        timeout         = time.Duration(sp.config.ScrapeTimeout)
        limit           = int(sp.config.SampleLimit)
        honorLabels     = sp.config.HonorLabels
        honorTimestamps = sp.config.HonorTimestamps
        mrc             = sp.config.MetricRelabelConfigs
    )

    sp.targetMtx.Lock()
    for _, t := range targets &#123;
        hash := t.hash()

        if _, ok := sp.activeTargets[hash]; !ok &#123;
            s := &amp;targetScraper&#123;Target: t, client: sp.client, timeout: timeout&#125;
            l := sp.newLoop(scrapeLoopOptions&#123;
                target:          t,
                scraper:         s,
                limit:           limit,
                honorLabels:     honorLabels,
                honorTimestamps: honorTimestamps,
                mrc:             mrc,
            &#125;)

            sp.activeTargets[hash] = t
            sp.loops[hash] = l

            uniqueLoops[hash] = l
        &#125; else &#123;
            // This might be a duplicated target.
            if _, ok := uniqueLoops[hash]; !ok &#123;
                uniqueLoops[hash] = nil
            &#125;
            // Need to keep the most updated labels information
            // for displaying it in the Service Discovery web page.
            sp.activeTargets[hash].SetDiscoveredLabels(t.DiscoveredLabels())
        &#125;
    &#125;

    var wg sync.WaitGroup

    // Stop and remove old targets and scraper loops.
    for hash := range sp.activeTargets &#123;
        if _, ok := uniqueLoops[hash]; !ok &#123;
            wg.Add(1)
            go func(l loop) &#123;
                l.stop()
                wg.Done()
            &#125;(sp.loops[hash])

            delete(sp.loops, hash)
            delete(sp.activeTargets, hash)
        &#125;
    &#125;

    sp.targetMtx.Unlock()

    targetScrapePoolTargetsAdded.WithLabelValues(sp.config.JobName).Set(float64(len(uniqueLoops)))
    forcedErr := sp.refreshTargetLimitErr()
    for _, l := range sp.loops &#123;
        l.setForcedError(forcedErr)
    &#125;
    for _, l := range uniqueLoops &#123;
        if l != nil &#123;
            go l.run(interval, timeout, nil)
        &#125;
    &#125;
    // Wait for all potentially stopped scrapers to terminate.
    // This covers the case of flapping targets. If the server is under high load, a new scraper
    // may be active and tries to insert. The old scraper that didn&#39;t terminate yet could still
    // be inserting a previous sample set.
    wg.Wait()
&#125;
</code></pre>
<p>这个方法现将Target转换成Loop，然后调用<code>go l.run(interval, timeout, nil)</code>开始抓取：</p>
<pre><code class="go">type loop interface &#123;
    run(interval, timeout time.Duration, errc chan&lt;- error)
    setForcedError(err error)
    stop()
    getCache() *scrapeCache
    disableEndOfRunStalenessMarkers()
&#125;
</code></pre>
<p>loop是一个interface，只要实现相应的方法都是loop。</p>
<p>run方法核心的在于调用scraper的scrape方法和report方法，scrape负责抓取，report负责数据上报，进行下一步的存储，scraper的定义如下：</p>
<pre><code class="go">type scraper interface &#123;
    scrape(ctx context.Context, w io.Writer) (string, error)
    Report(start time.Time, dur time.Duration, err error)
    offset(interval time.Duration, jitterSeed uint64) time.Duration
&#125;
</code></pre>
<p>具体实现的是targetScraper，定义如下：</p>
<pre><code class="go">type targetScraper struct &#123;
    *Target

    client  *http.Client
    req     *http.Request
    timeout time.Duration

    gzipr *gzip.Reader
    buf   *bufio.Reader
&#125;
</code></pre>
<pre><code class="go">func (s *targetScraper) scrape(ctx context.Context, w io.Writer) (string, error) &#123;
    if s.req == nil &#123;
        req, err := http.NewRequest(&quot;GET&quot;, s.URL().String(), nil)
        if err != nil &#123;
            return &quot;&quot;, err
        &#125;
        req.Header.Add(&quot;Accept&quot;, acceptHeader)
        req.Header.Add(&quot;Accept-Encoding&quot;, &quot;gzip&quot;)
        req.Header.Set(&quot;User-Agent&quot;, userAgentHeader)
        req.Header.Set(&quot;X-Prometheus-Scrape-Timeout-Seconds&quot;, fmt.Sprintf(&quot;%f&quot;, s.timeout.Seconds()))

        s.req = req
    &#125;

    resp, err := s.client.Do(s.req.WithContext(ctx))
    if err != nil &#123;
        return &quot;&quot;, err
    &#125;
    defer func() &#123;
        io.Copy(ioutil.Discard, resp.Body)
        resp.Body.Close()
    &#125;()

    if resp.StatusCode != http.StatusOK &#123;
        return &quot;&quot;, errors.Errorf(&quot;server returned HTTP status %s&quot;, resp.Status)
    &#125;

    if resp.Header.Get(&quot;Content-Encoding&quot;) != &quot;gzip&quot; &#123;
        _, err = io.Copy(w, resp.Body)
        if err != nil &#123;
            return &quot;&quot;, err
        &#125;
        return resp.Header.Get(&quot;Content-Type&quot;), nil
    &#125;

    if s.gzipr == nil &#123;
        s.buf = bufio.NewReader(resp.Body)
        s.gzipr, err = gzip.NewReader(s.buf)
        if err != nil &#123;
            return &quot;&quot;, err
        &#125;
    &#125; else &#123;
        s.buf.Reset(resp.Body)
        if err = s.gzipr.Reset(s.buf); err != nil &#123;
            return &quot;&quot;, err
        &#125;
    &#125;

    _, err = io.Copy(w, s.gzipr)
    s.gzipr.Close()
    if err != nil &#123;
        return &quot;&quot;, err
    &#125;
    return resp.Header.Get(&quot;Content-Type&quot;), nil
&#125;
</code></pre>
<p>我们终于看到，最后的最后，抓取其实是一个HTTP请求。为了完成一个抓取，Prometheus server进行了复杂的转化过程，正是这种实现，才让Prometheus拥有动态管理抓取目标的能力，我们大概来回忆一下这个转化过程：</p>
<pre><code class="go">Group --------
   |           \
   |             -&gt; scrapePool -&gt; pool -&gt; scraper
   |           /
Tatget ------- 
</code></pre>
<p>终于，我们把Prometheus server的抓取过程翻了个底朝天，裨益甚多。</p>
<p>那么数据抓取过来就是存储、分析和展示了，下一篇我们开始研究存储。</p>
</div>
    </div>

    <div class="post-meta">
        <i>
        
            <span>2021-03-22</span>
            
                <span>该篇文章被 Bray Wang</span>
            
            
                <span>打上标签:
                    
                    
                        <a href='/tags/Golang-Prometheus-Observability/'>
                            Golang, Prometheus, Observability
                        </a>
                    
                </span>
             
             
                <span>归为分类:
                    
                    
                        <a href='/categories/Golang/'>
                            Golang
                        </a>
                    
                </span>
            
        
        </i>
    </div>
    <br>
    
    
        
            
    
            <div class="post-footer-pre-next">
                
                    <span>上一篇：<a href='/2021/06/06/%E8%AF%B4%E8%AF%B4k8s%E7%BD%91%E7%BB%9C/'>说说k8s网络</a></span>
                

                
                    <span class="post-footer-pre-next-last-span-right">下一篇：<a href="/2021/03/20/Prometheus%E5%86%85%E9%83%A8%E5%AE%9E%E7%8E%B0-%E4%B8%89/">Prometheus内部实现(三)</a>
                    </span>
                
            </div>
    
        
    

    
        

     
</div>



                                      
                    
                    
                    <div class="footer">
    
        <span> 
            © Jerry Wang 

            
                

            
        </span>
       
    
</div>



<!--这是指一条线往下的内容-->
<div class="footer-last">
    
            <span>☀️白驹过隙,时光荏苒🌛</span>
            
                <span class="footer-last-span-right"><i>本站由<a target="_blank" rel="noopener" href="https://hexo.io/zh-cn/index.html">Hexo</a>驱动｜使用<a target="_blank" rel="noopener" href="https://github.com/HiNinoJay/hexo-theme-A4">Hexo-theme-A4</a>主题</i></span>
            
    
</div>


    
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.0/jquery.min.js"></script>

    <!--目录-->
    
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/1.7.2/jquery.min.js" type="text/javascript" ></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jqueryui/1.12.1/jquery-ui.min.js" type="text/javascript" ></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.tocify/1.9.0/javascripts/jquery.tocify.min.js" type="text/javascript" ></script>
        
<script src="/js/toc.js"></script>

    

    
<script src="/js/randomHeaderContent.js"></script>

    <!--回到顶部按钮-->
    
        
<script src="/js/returnToTop.js"></script>

    

    
        
<script src="/js/returnToLastPage.js"></script>

    





<script src="/js/lightgallery/lightgallery.umd.min.js"></script>



<script src="/js/lightgallery/plugins/lg-thumbnail.umd.min.js"></script>



<script src="/js/lightgallery/plugins/lg-fullscreen.umd.min.js"></script>


<script src="/js/lightgallery/plugins/lg-autoplay.umd.min.js"></script>


<script src="/js/lightgallery/plugins/lg-zoom.umd.min.js"></script>


<script src="/js/lightgallery/plugins/lg-rotate.umd.min.js"></script>


<script src="/js/lightgallery/plugins/lg-paper.umd.min.js"></script>




<script type="text/javascript">
     
    if (typeof lightGallery !== "undefined") {
        var options1 = {
            selector: '.gallery-item',
            plugins: [lgThumbnail, lgFullscreen, lgAutoplay, lgZoom, lgRotate, lgPager], // 启用插件
            thumbnail: true,          // 显示缩略图
            zoom: true,               // 启用缩放功
            rotate: true,             // 启用旋转功能能
            autoplay: true,        // 启用自动播放功能
            fullScreen: true,      // 启用全屏功能
            pager: false, //页码,
            zoomFromOrigin: true,   // 从原始位置缩放
            actualSize: true,       // 启用查看实际大小的功能
            enableZoomAfter: 300,    // 延迟缩放，确保图片加载完成后可缩放
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options1); // 修复选择器
    }
    
</script>


    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script> 

                </div>
            
            
                <!-- 回到顶部的按钮-->  
                <div class="progress-wrap shadow-drop-2-bottom">
                    <svg class="progress-circle svg-content" width="100%" height="100%" viewBox="-1 -1 102 102">
                        <path d="M50,1 a49,49 0 0,1 0,98 a49,49 0 0,1 0,-98"/>
                    </svg>
                </div>
            
            
                <!-- 返回的按钮-->  
                <div class="return-to-last-progress-wrap shadow-drop-2-bottom">
                    <svg class="progress-circle svg-content" width="100%" height="100%" viewBox="-1 -1 102 102">
                        <path d="M50,1 a49,49 0 0,1 0,98 a49,49 0 0,1 0,-98"/>
                    </svg>
                </div>
            
    </body>
</html>